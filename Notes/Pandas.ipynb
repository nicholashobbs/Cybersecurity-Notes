{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "python's version of excel, or pythons version of r data frames\n",
    "\n",
    "## Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "labels = ['a','b','c']\n",
    "my_data = [10,20,30]\n",
    "arr = np.array(my_data)\n",
    "d= {'a':10, 'b':20, 'c':30}\n",
    "\n",
    "pd.Series(data = my_data)\n",
    "\n",
    "pd.Series(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(my_data,labels)\n",
    "\n",
    "ser1 = pd.Series([1,2,3,4],['U','A','B','C'])\n",
    "\n",
    "ser1['U']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas always converts integers to floats\n",
    "\n",
    "## Data Frames\n",
    "the true workhorse of pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import randn\n",
    "np.random.seed(101)\n",
    "\n",
    "df = pd.DataFrame(randn(5,4),['A','B','C','D','E'],['W','X','Y','Z'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows and columns are sets of series that share the same index!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['W']\n",
    "\n",
    "df[['W','Z']]\n",
    "\n",
    "type(df['W']) # check what kind of data structure you're using\n",
    "\n",
    "df['new'] = df['W']+df['Y']\n",
    "\n",
    "df\n",
    "\n",
    "df.drop('new', axis=1)\n",
    "\n",
    "df.loc['C']\n",
    "\n",
    "df.iloc[2]\n",
    "\n",
    "df.loc['B','Y']\n",
    "\n",
    "df.loc[['A','B'],['W','Y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditional selection using bracket notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df>0]\n",
    "\n",
    "df[df['W']>0]\n",
    "\n",
    "df[df['W']>0][['Y','X']] # this type of notation doesn require memory, whereas the same thing written with definitions does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "you can't use the normal and operator, you have to use & for lists - since pythons boolean can only handle one thing at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['W']>0) | (df['Y']>1)]\n",
    "\n",
    "df[(df['W']>0) & (df['Y']>1)]\n",
    "\n",
    "# df.drop(['level_0','index','new'], axis=1, inplace=True)\n",
    "\n",
    "df\n",
    "\n",
    "states = 'UT AZ NV CA WA'.split()\n",
    "\n",
    "df['States'] = states\n",
    "\n",
    "# for SF salaries dataset\n",
    "# sal.loc[sal['EmployeeName']=='JOSEPH DRISCOLL']['JobTitle']\n",
    "# sal.groupby('Year').mean()['BasePay']\n",
    "# sal['JobTitle'].value_counts().head(5)\n",
    "# sum(sal[sal['Year']==2013]['JobTitle'].value_counts()==1)\n",
    "\n",
    "df.set_index('States')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi-index and index hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outside = ['G1','G1','G1','G2','G2','G2']\n",
    "inside = [1,2,3,1,2,3]\n",
    "hier_index = list(zip(outside,inside))\n",
    "hier_index = pd.MultiIndex.from_tuples(hier_index)\n",
    "\n",
    "df = pd.DataFrame(randn(6,2),hier_index,['A','B'])\n",
    "\n",
    "df\n",
    "\n",
    "df.loc['G1']\n",
    "\n",
    "df.index.names = ['Groups','Num']\n",
    "\n",
    "df\n",
    "\n",
    "df.loc['G1'].loc[3]['A']\n",
    "\n",
    "df.xs(1,level='Num') # has the ability to skip or go inside a dataframe\n",
    "\n",
    "Missing Data\n",
    "\n",
    "d = {'A':[1,2,np.nan],'B':[5,np.nan,np.nan],'C':[1,2,3]}\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "\n",
    "df\n",
    "\n",
    "df.dropna(axis=1)\n",
    "\n",
    "df.dropna()\n",
    "\n",
    "df.dropna(thresh=2)\n",
    "\n",
    "df['A'].fillna(value=df['A'].mean())\n",
    "\n",
    "data = {'Company':['GOOG','GOOG','MSFT','MSFT','FB','FB'],\n",
    "       'Person':['Sam','Charlie','Amy','Vanessa','Carl','Sarah'],\n",
    "       'Sales':[200,120,340,124,243,350]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "byComp = df.groupby('Company')\n",
    "\n",
    "byComp.mean()\n",
    "\n",
    "byComp.sum()\n",
    "\n",
    "byComp.sum().loc['FB']\n",
    "\n",
    "df.groupby('Company').describe().transpose()\n",
    "\n",
    "df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                        'B': ['B0', 'B1', 'B2', 'B3'],\n",
    "                        'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                        'D': ['D0', 'D1', 'D2', 'D3']},\n",
    "                        index=[0, 1, 2, 3])\n",
    "\n",
    "df2 = pd.DataFrame({'A': ['A4', 'A5', 'A6', 'A7'],\n",
    "                        'B': ['B4', 'B5', 'B6', 'B7'],\n",
    "                        'C': ['C4', 'C5', 'C6', 'C7'],\n",
    "                        'D': ['D4', 'D5', 'D6', 'D7']},\n",
    "                         index=[4, 5, 6, 7]) \n",
    "\n",
    "df3 = pd.DataFrame({'A': ['A8', 'A9', 'A10', 'A11'],\n",
    "                        'B': ['B8', 'B9', 'B10', 'B11'],\n",
    "                        'C': ['C8', 'C9', 'C10', 'C11'],\n",
    "                        'D': ['D8', 'D9', 'D10', 'D11']},\n",
    "                        index=[8, 9, 10, 11])\n",
    "\n",
    "pd.concat([df1,df2,df3])\n",
    "\n",
    "left = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],\n",
    "                     'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                     'B': ['B0', 'B1', 'B2', 'B3']})\n",
    "   \n",
    "right = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],\n",
    "                          'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                          'D': ['D0', 'D1', 'D2', 'D3']})\n",
    "\n",
    "pd.merge(left,right,how='inner',on='key')\n",
    "\n",
    "joining - keys you want to join on are index rather than columns\n",
    "\n",
    "left = pd.DataFrame({'A': ['A0', 'A1', 'A2'],\n",
    "                     'B': ['B0', 'B1', 'B2']},\n",
    "                      index=['K0', 'K1', 'K2']) \n",
    "\n",
    "right = pd.DataFrame({'C': ['C0', 'C2', 'C3'],\n",
    "                    'D': ['D0', 'D2', 'D3']},\n",
    "                      index=['K0', 'K2', 'K3'])\n",
    "\n",
    "left.join(right)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'col1':[1,2,3,4],'col2':[444,555,666,444],'col3':['abc','def','ghi','xyz']})\n",
    "df.head()\n",
    "\n",
    "df['col2'].unique()\n",
    "\n",
    "df['col2'].nunique()\n",
    "\n",
    "def times2(x):\n",
    "    return x*2\n",
    "\n",
    "df['col1'].apply(times2)\n",
    "\n",
    "df['col1'].apply(lambda x: x*2)\n",
    "\n",
    "df.columns\n",
    "\n",
    "df.sort_values('col2')\n",
    "\n",
    "data = {'A':['foo','foo','foo','bar','bar','bar'],\n",
    "     'B':['one','one','two','two','one','one'],\n",
    "       'C':['x','y','x','y','x','y'],\n",
    "       'D':[1,3,2,5,4,1]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.pivot_table(values='D',index=['A','B'],columns=['C'])\n",
    "\n",
    "pwd\n",
    "\n",
    "df = pd.read_csv('example') #csv\n",
    "\n",
    "df.to_csv('my_output',index=False)\n",
    "\n",
    "df\n",
    "\n",
    "pd.read_excel('Excel_Sample.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "df.to_excel('Excel_Sample2.xlsx',sheet_name='NewSheet')\n",
    "\n",
    "data = pd.read_html('http://www.fdic.gov/bank/individual/failed/banklist.html')\n",
    "\n",
    "data[0]\n",
    "\n",
    "use specific library for whatever your flavor of sql is - for example:\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('sqlite:///:memory:')\n",
    "\n",
    "df.to_sql('my_table',engine)\n",
    "\n",
    "sqldf = pd.read_sql('my_table', con=engine)\n",
    "\n",
    "sqldf\n",
    "\n",
    "sqldf.columns\n",
    "sqldf.index\n",
    "sqldf.info()\n",
    "\n",
    "ecom['Email'].apply(lambda email: email.split('@')[1]).value_counts().head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
